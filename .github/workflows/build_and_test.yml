name: CI / Docs / Deploy

on:
  pull_request:
  push:
    branches: [ main ]
    tags: [ "v*", "test-*" ]
  # Run benchmarks every night at 2am UTC
  schedule:
    - cron: '0 2 * * *'
  # Allow manual runs from the Actions tab
  workflow_dispatch:

jobs:
  # ==========================================================================
  # 0. LINT JOB (Fast checks via pre-commit)
  # ==========================================================================
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Install Python 3.12
        run: uv python install 3.12

      - name: Install dependencies
        run: |
          # Install 'dev' dependencies (includes pre-commit, ruff, mypy)
          uv venv
          uv pip install ".[dev]"

      - name: Run Pre-commit
        run: |
          source .venv/bin/activate
          # This runs ruff, mypy, and all other hooks defined in your .pre-commit-config.yaml
          pre-commit run --all-files

  # ==========================================================================
  # 1. TEST JOB (Self-Hosted GPU Runner)
  # ==========================================================================
  test:
    runs-on: self-hosted
    strategy:
      fail-fast: false
      matrix:
        include:
          - py: "python"
            ver: "3.12"
          - py: "python"
            ver: "3.11"
          - py: "python"
            ver: "3.10"

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3
        with:
          enable-cache: true

      - name: Locate ${{ matrix.py }}
        shell: bash
        run: |
          set -euo pipefail
          if command -v ${{ matrix.py }} >/dev/null 2>&1; then
            echo "âœ… Found system ${{ matrix.py }}"
            echo "PYTHON_PATH=$(command -v ${{ matrix.py }})" >> $GITHUB_ENV
          else
            echo "âš ï¸ System ${{ matrix.py }} not found. Installing managed version..."
            uv python install ${{ matrix.ver }}
            echo "PYTHON_PATH=$(uv python find ${{ matrix.ver }})" >> $GITHUB_ENV
          fi

      - name: Install & Test
        shell: bash
        run: |
          set -euo pipefail
          echo "Using interpreter: $PYTHON_PATH"

          # --system-site-packages links against pre-installed CUDA libs
          uv venv --python "$PYTHON_PATH" --system-site-packages .venv
          source .venv/bin/activate

          # Install package + test suite
          uv pip install ".[test]"

          pytest -q

      - name: Post-Test Cleanup
        if: always() # Runs even if tests fail
        run: |
          echo "ðŸ§¹ Cleaning up test artifacts..."
          # Remove the venv to save space (it's recreated every run anyway)
          rm -rf .venv
          # Clean uv cache to prevent indefinite growth
          uv cache prune --ci

  # ==========================================================================
  # 2. BENCHMARK JOB (Self-Hosted GPU Runner)
  #    - Runs on Push, Schedule, or Manual Trigger
  # ==========================================================================
  benchmark:
    needs: [test]
    runs-on: self-hosted # Requires GPU
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v3

      - name: Locate Python 3.12
        shell: bash
        run: |
          if command -v python3.12 >/dev/null 2>&1; then
             echo "PYTHON_PATH=$(command -v python3.12)" >> $GITHUB_ENV
          else
             uv python install 3.12
             echo "PYTHON_PATH=$(uv python find 3.12)" >> $GITHUB_ENV
          fi

      - name: Run Benchmarks
        shell: bash
        run: |
          set -euo pipefail
          uv venv --python "$PYTHON_PATH" --system-site-packages .venv
          source .venv/bin/activate

          # Install dependencies for the benchmark script
          uv pip install ".[test]" pandas plotly pytket-qiskit pytket-qulacs kaleido

          # This prevents the Python script from having to do network calls during execution
          kaleido_get_chrome

          # Run the script (Generates docs/assets/benchmark_*.html)
          python benchmarks/benchmark.py

      - name: Upload Benchmark Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-plots
          path: docs/assets/benchmark_*.html
          retention-days: 1

      - name: Post-Benchmark Cleanup
        if: always()
        run: |
          echo "ðŸ§¹ Cleaning up benchmark artifacts..."
          rm -rf .venv
          rm -rf docs/assets/benchmark_*.html
          uv cache prune --ci

  # ==========================================================================
  # 3. DOCS JOB (Standard Runner)
  #    - Downloads plots -> Builds Site -> Deploys
  # ==========================================================================
  docs:
    name: Build & Deploy Docs
    needs: [benchmark]
    runs-on: ubuntu-latest
    permissions:
      contents: write

    steps:
      - uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v3

      - name: Set up Python 3.12
        run: uv python install 3.12

      # ðŸ“¥ RETRIEVE THE BENCHMARK PLOTS
      - name: Download Benchmark Plots
        uses: actions/download-artifact@v6
        with:
          name: benchmark-plots
          path: docs/assets/

      - name: Install Docs Dependencies
        run: |
          uv venv
          source .venv/bin/activate
          uv pip install ".[docs]"

      - name: Build Docs (Validation)
        run: |
          source .venv/bin/activate
          mkdocs build -s

      - name: Deploy (Main Branch / Schedule / Manual)
        # Deploy if it is a Push to Main, OR a Scheduled run, OR a Manual trigger
        if: |
          github.ref == 'refs/heads/main' &&
          (github.event_name == 'push' || github.event_name == 'schedule' || github.event_name == 'workflow_dispatch')
        run: |
          source .venv/bin/activate
          git config user.name ci-bot
          git config user.email ci-bot@quantinuum.com

          # Standard deployment
          mkdocs gh-deploy --force

  # ==========================================================================
  # 4. PUBLISH JOBS (TestPyPI & PyPI)
  # ==========================================================================
  publish-testpypi:
    if: startsWith(github.ref, 'refs/tags/test-')
    needs: [test]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v3
      - name: Build
        run: |
          uv python install 3.12
          uv build
          uvx twine check dist/*
      - name: Upload
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          user: __token__
          password: ${{ secrets.TEST_PYPI_API_TOKEN }}
          repository-url: https://test.pypi.org/legacy/

  publish-pypi:
    if: startsWith(github.ref, 'refs/tags/v')
    needs: [test]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps:
      - uses: actions/checkout@v4
      - uses: astral-sh/setup-uv@v3
      - name: Build
        run: |
          uv python install 3.12
          uv build
          uvx twine check dist/*
      - name: Upload
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          user: __token__
          password: ${{ secrets.PYPI_API_TOKEN }}
